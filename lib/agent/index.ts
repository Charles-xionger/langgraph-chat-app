import { AgentConfigOptions } from "@/types/agent";
import { postgresCheckpointer } from "./memory";
import { AgentBuilder } from "./builder";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { SYSTEM_PROMPT } from "./prompt";
import { getInternalTools } from "./tools";
import { DynamicTool } from "langchain";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { ChatAlibabaTongyi } from "@langchain/community/chat_models/alibaba_tongyi";
import { MultiServerMCPClient } from "@langchain/mcp-adapters";

// ç”¨æ¥æ ‡è®°æ˜¯å¦å·²ç»å¼€å§‹è®¾ç½®
let setupPromise: Promise<void> | null = null;

/**
 * ç¡®ä¿ PostgresSaver å·²ç»è®¾ç½®å®Œæˆ
 */
async function setupOnce() {
  if (!setupPromise) {
    setupPromise = postgresCheckpointer.setup().catch((error) => {
      setupPromise = null;
      throw error;
    });
  }
  await setupPromise;
}

// MCP å·¥å…·ç¼“å­˜ - ä¿ç•™ä»¥æé«˜ MCP å·¥å…·åŠ è½½æ€§èƒ½
const mcpToolsCache = new Map<string, DynamicTool[]>();

/**
 *
 * @description åˆ›å»ºèŠå¤©Model
 *
 *
 * TODO åæœŸå¯è¿›è¡Œæ‰©å±•
 */

interface ChatModelOptions {
  provider?: string;
  model?: string;
  temperature?: number;
}
function createChatModel({
  provider = "openai",
  model,
  temperature = 1,
}: ChatModelOptions) {
  console.log("Creating chat model:", { provider, model });

  switch (provider) {
    case "aliyun":
      return new ChatOpenAI({
        model,
        temperature,
        apiKey: process.env.ALIYUN_API_KEY,
        configuration: {
          baseURL: process.env.ALIYUN_BASE_URL,
        },
      });
    case "openai":
      return new ChatOpenAI({
        modelName: "gpt-4.1",
        temperature: temperature,
      });

    case "gemini":
      console.log("Using Gemini model");
      return new ChatGoogleGenerativeAI({
        model: process.env.GOOGLE_MODEL_NAME || "gemini-3-pro-image-preview",
        apiKey: process.env.GOOGLE_API_KEY,
        temperature: 0.7,
        streaming: true, // å¯ç”¨æµå¼å“åº”
      });
    default:
      return new ChatOpenAI({
        modelName: "gpt-4.1",
        temperature: temperature,
      });
      break;
  }
}

function createEmbeddingsModel() {
  return new OpenAIEmbeddings({
    model: "text-embedding-3-small",
  });
}

/**
 * åˆ›å»ºæ–°çš„ agent å®ä¾‹æ ¹æ®æä¾›çš„é…ç½®
 * æ³¨æ„ï¼šæ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºæ–°å®ä¾‹ï¼Œé¿å… Vercel Serverless å¤šå®ä¾‹é—´çš„çŠ¶æ€æ±¡æŸ“
 *
 * @param config - é…ç½®å¯¹è±¡
 * @returns æ–°çš„ agent å®ä¾‹
 */
export async function createAgent(config?: AgentConfigOptions) {
  const provider = config?.provider || "openai";
  const model =
    config?.model ||
    (provider === "aliyun" ? process.env.ALIYUN_MODEL_NAME : "gpt-4.1");

  console.log(
    `ğŸ†• Creating new agent instance - Provider: ${provider}, Model: ${model}`
  );

  const llm = createChatModel({ provider, model });

  // MCP Tools - ä»é…ç½®ä¸­è·å– MCP URL
  let mcptools: DynamicTool[] = [];

  if (config?.mcpUrl) {
    // å…ˆæ£€æŸ¥ç¼“å­˜
    if (mcpToolsCache.has(config.mcpUrl)) {
      mcptools = mcpToolsCache.get(config.mcpUrl)!;
      console.log(`âœ… ä½¿ç”¨ç¼“å­˜çš„ MCP å·¥å…·: ${mcptools.length} ä¸ª`);
    } else {
      // ä» MCP æœåŠ¡å™¨åŠ è½½
      try {
        console.log(`ğŸ”„ ä»æœåŠ¡å™¨åŠ è½½ MCP å·¥å…·: ${config.mcpUrl}`);
        const startTime = Date.now();

        const client = new MultiServerMCPClient({
          mcpServer: {
            transport: "http",
            url: config.mcpUrl,
          },
        });

        const tools = await client.getTools();
        mcptools = tools as any as DynamicTool[];

        const loadTime = Date.now() - startTime;
        console.log(
          `âœ… æˆåŠŸåŠ è½½ ${mcptools.length} ä¸ª MCP å·¥å…· (è€—æ—¶: ${loadTime}ms)`
        );

        // ç¼“å­˜å·¥å…·
        mcpToolsCache.set(config.mcpUrl, mcptools);

        // æ‰“å°æ¯ä¸ªå·¥å…·çš„è¯¦ç»†ä¿¡æ¯
        mcptools.forEach((tool, index) => {
          console.log(`ğŸ”§ MCP å·¥å…· #${index + 1}:`, {
            name: tool.name,
            description: tool.description,
            schema: tool.schema,
          });
        });
      } catch (error) {
        console.error("âŒ åŠ è½½ MCP å·¥å…·å¤±è´¥:", error);
      }
    }
  }

  // å†…ç½®å·¥å…·
  const internalTools = getInternalTools(llm, createEmbeddingsModel());

  const allTools = [...internalTools, ...mcptools] as DynamicTool[];

  const agent = new AgentBuilder({
    llm,
    tools: allTools,
    prompt: config?.systemPrompt || SYSTEM_PROMPT,
    checkpointer: postgresCheckpointer,
  }).buildWithApproval(); // ä½¿ç”¨å¸¦å®¡æ‰¹åŠŸèƒ½çš„æ„å»ºæ–¹æ³•ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å®¡æ‰¹

  console.log(`âœ… Agent instance created successfully`);

  return agent;
}

/**
 * ç¡®ä¿ checkpointer å·²åˆå§‹åŒ–å¹¶åˆ›å»ºæ–°çš„ agent å®ä¾‹
 * æ³¨æ„ï¼šä¸å†ä½¿ç”¨ç¼“å­˜ï¼Œæ¯æ¬¡éƒ½åˆ›å»ºæ–°å®ä¾‹ä»¥é¿å… Vercel å¤šå®ä¾‹çŠ¶æ€é—®é¢˜
 */
export async function ensureAgent(config?: AgentConfigOptions) {
  // ç¡®ä¿ checkpointer å·²ç»å®Œæˆåˆå§‹åŒ–
  await setupOnce();

  // ç›´æ¥åˆ›å»ºæ–°çš„ agent å®ä¾‹ï¼Œä¸ä½¿ç”¨ç¼“å­˜
  return await createAgent(config);
}

// æ˜¾å¼è·å–é…ç½®å¥½çš„ Agent çš„å‘½åå¯¼å‡º
export async function getAgent(config?: AgentConfigOptions) {
  return ensureAgent(config);
}
